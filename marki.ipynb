{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.probe_confidence_intervals import model_setup, get_activations\n",
    "from utils.preprocessing import load_txt_data\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "class HookManager2():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.hooks = []\n",
    "\n",
    "    def attach_residstream_hook(self, layer, pre_mlp=False, pythia=False):\n",
    "        if pre_mlp:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.mlp'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.mlp'\n",
    "        else:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.attention'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.attn'\n",
    "        \n",
    "        extracted_output = []\n",
    "        def residstream_hook(module, input, output):\n",
    "            extracted_output.append(input[0].squeeze(0).detach())\n",
    "\n",
    "        self.hooks.append(\n",
    "            self.model.get_submodule(hookpoint).register_forward_hook(residstream_hook)\n",
    "        )\n",
    "\n",
    "        return extracted_output\n",
    "    \n",
    "    def attach_resid_stream_steer_hook(self, layer, steering_vector, scalar, pre_mlp=False, pythia=False):\n",
    "        if pre_mlp:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.mlp'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.mlp'\n",
    "        else:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.attention'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.attn'\n",
    "\n",
    "\n",
    "\n",
    "        def steering_hook(module, input):\n",
    "            activation = input[0]\n",
    "\n",
    "            steering_norm = steering_vector / torch.norm(steering_vector)\n",
    "            \n",
    "            projection_magnitudes = (activation @ steering_norm).unsqueeze(-1)\n",
    "            \n",
    "            steering_norm_ = steering_norm.view(1, 1, -1)\n",
    "\n",
    "            projections = projection_magnitudes * steering_norm_\n",
    "\n",
    "            modified = activation + scalar * projections\n",
    "\n",
    "            act_norm = torch.norm(activation, dim=2).unsqueeze(-1)\n",
    "            modified_norm = torch.norm(activation, dim=2).unsqueeze(-1)\n",
    "\n",
    "            modified = modified * (act_norm / modified_norm)\n",
    "\n",
    "            return (modified,) + input[1:] if len(input) > 1 else (modified,)\n",
    "        \n",
    "        self.hooks.append(\n",
    "            self.model.get_submodule(hookpoint).register_forward_pre_hook(steering_hook)\n",
    "        )\n",
    "        \n",
    "    def attach_residual_stream_steering_vector(self, layer, steering_vector, plus, pre_mlp=False, pythia=False):\n",
    "        #This is martins' \n",
    "        \n",
    "        if pre_mlp:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.mlp'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.mlp'\n",
    "        else:\n",
    "            if pythia:\n",
    "                hookpoint = f'gpt_neox.layers.{layer}.attention'\n",
    "            else:\n",
    "                hookpoint = f'transformer.h.{layer}.attn'\n",
    "        \n",
    "        def steering_hook(module, input):\n",
    "            activation = input[0]\n",
    "            if plus:\n",
    "                activation = activation + steering_vector\n",
    "            else:\n",
    "                activation = activation - steering_vector\n",
    "            return activation\n",
    "\n",
    "        self.hooks.append(\n",
    "            self.model.get_submodule(hookpoint).register_forward_pre_hook(steering_hook)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "Load data\n"
     ]
    }
   ],
   "source": [
    "print(\"Load model\")\n",
    "model_name  = \"AI-Sweden-Models/gpt-sw3-356m\"\n",
    "\n",
    "model, tokenizer, device = model_setup(model_name)\n",
    "\n",
    "raw_data_folder = Path('data/antibiotic/')\n",
    "print(\"Load data\")\n",
    "ds = load_txt_data(\n",
    "    file_paths={\n",
    "        'da': raw_data_folder / 'da.txt',\n",
    "        'en': raw_data_folder / 'en.txt',\n",
    "        'sv': raw_data_folder / 'sv.txt',\n",
    "        'nb': raw_data_folder / 'nb.txt',\n",
    "        'is': raw_data_folder / 'is.txt'\n",
    "    },\n",
    "    file_extension='txt'\n",
    ")\n",
    "\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {}\n",
    "meta_data[\"hidden_layers\"] = model.config.num_hidden_layers\n",
    "\n",
    "try:\n",
    "    meta_data[\"hidden_size\"] = model.config.n_embd\n",
    "except AttributeError:\n",
    "    meta_data[\"hidden_size\"] = model.config.hidden_size\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4/26 [00:28<02:25,  6.60s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_steering_vectors(ds, \n",
    "                         languages:list,\n",
    "                         meta_data,\n",
    "                         tokenizer,\n",
    "                         device,\n",
    "                         model):\n",
    "    d = dict()\n",
    "    for lang in languages:\n",
    "        \n",
    "        ds = ds.filter_by_language(lang)\n",
    "        loader = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "        activation_ds_by_layer = get_activations(meta_data,loader, tokenizer, device, model)\n",
    "        d[lang] = [layer.predictors for layer in activation_ds_by_layer]\n",
    "    return d\n",
    "languages = [\"da\",\"en\"]\n",
    "get_steering_vectors(ds,languages,meta_data, tokenizer, device, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  5%|▍         | 6/130 [00:40<13:52,  6.71s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = activation_ds_by_layer[0].predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_steering = torch.stack(english).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why can we subtract a feature but not aplify a feature\n",
    "#talk about other steering method https://arxiv.org/html/2402.01618v1#S3.SS1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a short story about 1898, when the young man who was to become a successful entrepreneur was at the height of his powers. In the novel, the protagonist is a young man who is trying to make his fortune. In this novel, the main character is a young man who is trying to make his fortune.\n",
      "\n",
      "This is a short story about 2 people who live in a small town and one day they get a letter from a school teacher saying that he has been the most evil person ever. He had been a bad person before but now he has become a great person. He is the most evil person in the world and he is so sad. He is\n",
      "\n",
      "This is a short story about 3 teenagers. The story is about a boy and his dog.    The boy's dog is a golden retriever.    The boy is going to school.    The boy's dog is going to school.    The boy is going to\n",
      "\n",
      "This is a short story about 4 brothers, 1 sister and 1 friend.  I just finished this book and I loved it.  It's a bit dark and a little sad but it's very well written and it's a good read.  It's about a boy named Jade who is 16\n",
      "\n",
      "This is a short story about 15-year-old girls who love animals, and a boy who loves animals. Lyrics for 15-year-old girls 15-year-old girls love animals 15-year-old girls love animals 15-year-old girls love animals 1\n",
      "\n",
      "This is a short story about 18th century England, a place of peace and quiet. The story was written by John Bacon, the son of John Bacon, the famous author of The Fountain of Youth. History. The story was written by John Bacon, the son of John Bacon, the famous author of\n",
      "\n",
      "This is a short story about 3 people who have a lot in common. The story is about the people who are always looking for something to talk about and the people who are always trying to make people happy. The people who are always looking for something to talk about are the people who are always looking for something to talk about.  In\n",
      "\n",
      "This is a short story about 16 year old John who has a girlfriend named Emma who is 18. He has a boyfriend called Jake who is 17. Emma is a very nice girl who he likes. She is also very beautiful. John is always at school. Jake is very good at school. One day John gets upset\n",
      "\n",
      "This is a short story about 100% of my life, I'm 17, and I've always been a fan of the movies. My favorite character is always the one that dies. He's the hero, but he's also the one who gets killed and the one who gets back in the movie.\n",
      "\n",
      "This is a short story about 100-year-old people living in a castle. The story is about the old woman who lived in the castle and her husband who was a servant. The story is about a castle and a man who lives in the castle.  Input: Sentence 1: The woman was very\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = 'This is a short story about '\n",
    "tokenized = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "with HookManager2(model) as hook_manager:\n",
    "    \n",
    "    hook_manager.attach_residual_stream_steering_vector(\n",
    "        6,\n",
    "        english_steering,\n",
    "        plus = False,\n",
    "        pre_mlp=False,\n",
    "        pythia=False\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "    output_nb_steering = [\n",
    "        model.generate(tokenized.input_ids, max_length=70, temperature=0.7, top_p=0.9, do_sample=True)\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "for output in output_nb_steering:\n",
    "    print(tokenizer.decode(output[0]).replace('\\n', ' '))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
