{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'da': ('I Begyndelsen skabte Gud Himmelen og Jorden.',\n",
       "  'Og Jorden var øde og tom, og der var Mørke over Verdensdybet. Men Guds Ånd svævede over Vandene.'),\n",
       " 'en': ('In the beginning God created the heavens and the earth.',\n",
       "  \"Now the earth was formless and empty. Darkness was on the surface of the deep. God's Spirit was hovering over the surface of the waters.\")}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dansk bibel                            \"bla bla (originalt danski)\" \n",
    "#engelsk bibel \"bla bla\" steering homie \"bla bla (men dansk)\"\n",
    "from huggingface_hub import hf_hub_download\n",
    "from utils.steering import generate_with_steering\n",
    "import fasttext\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM\n",
    "from classes.datahandling import ParallelNSPDataset\n",
    "from utils.probe_confidence_intervals import model_setup\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from fasttext.FastText import _FastText\n",
    "\n",
    "\n",
    "model, tokenizer, device = model_setup(\"AI-Sweden-Models/gpt-sw3-356m\")\n",
    "\n",
    "model_name = \"nb-nordic-lid.ftz\"\n",
    "language_prediction_model = fasttext.load_model(hf_hub_download(\"NbAiLab/nb-nordic-lid\", model_name))\n",
    "\n",
    "label, score = language_prediction_model.predict(\"Harry Potter är en serie fantasyromaner av författaren J.K. Rowling, som började ges\", threshold=0.25)\n",
    "label[0].split(\"__\")[-1], score\n",
    "bible_data = ParallelNSPDataset.from_tmx(\"data/bible-da-en.tmx\",\"da\",\"en\")\n",
    "bible_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Path to your model files\n",
    "model_path = 'gpt_gptsw3_en_no_is_da_356m_gbs1024'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hej med dig.\n",
      "-Jeg er ikke sikker på, at jeg kan klare det.\n",
      "-Det er jeg\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\"hej med dig\",return_tensors= \"pt\")\n",
    "out = model.generate(tokenized.input_ids, pad_token_id=tokenizer.eos_token_id,max_new_tokens = 20)\n",
    "print(tokenizer.decode(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
