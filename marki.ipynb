{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"gpt_gptsw3_en_da_356m_gbs1024\",\"gpt_gptsw3_en_da_is_356m_gbs1024\",\"gpt_gptsw3_en_is_da_356m_gbs1024\",\"gpt_sw3_356m\"]\n",
    "\n",
    "layer = \"transformer.h.15.ln_1.bias\"\n",
    "for model_name in model_names:\n",
    "    \n",
    "    model_path = \"downloaded_models/\"\n",
    "\n",
    "    model, tokenizer, device = model_setup(f\"{model_path}{model_name}\")\n",
    "    \n",
    "    steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n",
    "    \n",
    "    model.state_dict()[layer] += steering\n",
    "    \n",
    "    model.save_pretrained(f'{model_path}/{model_name}_with_steering')\n",
    "    tokenizer.save_pretrained(f'{model_path}/{model_name}_with_steering')  # Optional but recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refactor.probes import model_setup\n",
    "import os\n",
    "from scipy.spatial.distance import euclidean, mahalanobis, cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from refactor.utils.hooking import HookManager\n",
    "from refactor.utils.compatibility import HookAddress\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "found device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from refactor.probes import model_setup\n",
    "import os\n",
    "from scipy.spatial.distance import euclidean, mahalanobis, cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from refactor.utils.hooking import HookManager\n",
    "from refactor.utils.compatibility import HookAddress\n",
    "\n",
    "# loads model\n",
    "print(\"Load model\") \n",
    "model_name = \"EleutherAI/pythia-14m\"\n",
    "model_name = \"AI-Sweden-Models/gpt-sw3-356m\"\n",
    "model, tokenizer, device = model_setup(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjupp\\AppData\\Local\\Temp\\ipykernel_10332\\3216484567.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  average_vectors[language] = torch.load(path + \"/\" + file)\n"
     ]
    }
   ],
   "source": [
    "average_vectors = dict()\n",
    "path = \"average_activation_vectors/gpt_sw3_356m\"\n",
    "layer = 15\n",
    "for file in os.listdir(path):\n",
    "    split = file.split(\"_\")\n",
    "    language = split[1]\n",
    "    layer_temp = split[3]\n",
    "    if int(layer_temp) == layer:\n",
    "        average_vectors[language] = torch.load(path + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cat (Felis catus), also referred to as the domestic cat or house cat, is a small domesticated carnivorous mammal. It is the only domesticated species of the family Felidae. Advances in archaeology and genetics have shown that the domestication of the cat occurred in the Near East around 7500 BC.\"\n",
    "text = \"Tamkatten (Felis catus[1][2] eller Felis silvestris catus[3]) er et lille, tæmmet, kødædende pattedyr oftest med pels. Den kaldes huskat eller bare kat, når der ikke er grund til at skelne den fra andre kattedyr. Katten er værdsat af mennesker for dens selskab og evne til at jage mus og rotter. Mange huskatte bliver op mod 20 år gamle.\"\n",
    "if tokenizer.pad_token == None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "with HookManager(model) as hook_manager:\n",
    "    extracted = hook_manager.extract(HookAddress.attention_pre.layer(layer))\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "                    text,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                ).to(device)\n",
    "\n",
    "    out = model(**tokenized)\n",
    "    del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0658])\n",
      "tensor([-0.0625])\n",
      "tensor([-0.0674])\n",
      "tensor([-0.0643])\n",
      "tensor([-0.0635])\n",
      "tensor([0.7799])\n",
      "tensor([0.7798])\n",
      "tensor([0.7739])\n",
      "tensor([0.7815])\n",
      "tensor([0.7826])\n",
      "tensor([0.7732])\n",
      "tensor([0.7730])\n",
      "tensor([0.7598])\n",
      "tensor([0.7759])\n",
      "tensor([0.7785])\n",
      "tensor([0.7998])\n",
      "tensor([0.8030])\n",
      "tensor([0.7878])\n",
      "tensor([0.8022])\n",
      "tensor([0.8033])\n",
      "tensor([0.8036])\n",
      "tensor([0.8042])\n",
      "tensor([0.7942])\n",
      "tensor([0.8055])\n",
      "tensor([0.8054])\n",
      "tensor([0.7667])\n",
      "tensor([0.7659])\n",
      "tensor([0.7563])\n",
      "tensor([0.7658])\n",
      "tensor([0.7681])\n",
      "tensor([0.7893])\n",
      "tensor([0.7887])\n",
      "tensor([0.7830])\n",
      "tensor([0.7883])\n",
      "tensor([0.7911])\n",
      "tensor([0.7781])\n",
      "tensor([0.7798])\n",
      "tensor([0.7684])\n",
      "tensor([0.7769])\n",
      "tensor([0.7806])\n",
      "tensor([0.7406])\n",
      "tensor([0.7436])\n",
      "tensor([0.7349])\n",
      "tensor([0.7418])\n",
      "tensor([0.7435])\n",
      "tensor([0.7895])\n",
      "tensor([0.7938])\n",
      "tensor([0.7775])\n",
      "tensor([0.7925])\n",
      "tensor([0.7902])\n",
      "tensor([0.7853])\n",
      "tensor([0.7886])\n",
      "tensor([0.7782])\n",
      "tensor([0.7888])\n",
      "tensor([0.7876])\n",
      "tensor([0.8057])\n",
      "tensor([0.8076])\n",
      "tensor([0.7936])\n",
      "tensor([0.8084])\n",
      "tensor([0.8051])\n",
      "tensor([0.8136])\n",
      "tensor([0.8159])\n",
      "tensor([0.8033])\n",
      "tensor([0.8158])\n",
      "tensor([0.8155])\n",
      "tensor([0.8088])\n",
      "tensor([0.8077])\n",
      "tensor([0.7970])\n",
      "tensor([0.8094])\n",
      "tensor([0.8114])\n",
      "tensor([0.7701])\n",
      "tensor([0.7667])\n",
      "tensor([0.7641])\n",
      "tensor([0.7697])\n",
      "tensor([0.7733])\n",
      "tensor([0.7650])\n",
      "tensor([0.7615])\n",
      "tensor([0.7548])\n",
      "tensor([0.7643])\n",
      "tensor([0.7655])\n",
      "tensor([0.7569])\n",
      "tensor([0.7568])\n",
      "tensor([0.7577])\n",
      "tensor([0.7557])\n",
      "tensor([0.7588])\n",
      "tensor([0.7461])\n",
      "tensor([0.7444])\n",
      "tensor([0.7458])\n",
      "tensor([0.7446])\n",
      "tensor([0.7468])\n",
      "tensor([0.7787])\n",
      "tensor([0.7773])\n",
      "tensor([0.7700])\n",
      "tensor([0.7771])\n",
      "tensor([0.7805])\n",
      "tensor([0.8167])\n",
      "tensor([0.8152])\n",
      "tensor([0.8124])\n",
      "tensor([0.8154])\n",
      "tensor([0.8181])\n",
      "tensor([0.7979])\n",
      "tensor([0.7979])\n",
      "tensor([0.7886])\n",
      "tensor([0.7969])\n",
      "tensor([0.7993])\n",
      "tensor([0.7714])\n",
      "tensor([0.7709])\n",
      "tensor([0.7652])\n",
      "tensor([0.7735])\n",
      "tensor([0.7719])\n",
      "tensor([0.7938])\n",
      "tensor([0.7939])\n",
      "tensor([0.7858])\n",
      "tensor([0.7952])\n",
      "tensor([0.7919])\n",
      "tensor([0.8074])\n",
      "tensor([0.8072])\n",
      "tensor([0.7926])\n",
      "tensor([0.8078])\n",
      "tensor([0.8094])\n",
      "tensor([0.8102])\n",
      "tensor([0.8048])\n",
      "tensor([0.7976])\n",
      "tensor([0.8108])\n",
      "tensor([0.8063])\n",
      "tensor([0.8068])\n",
      "tensor([0.8013])\n",
      "tensor([0.7912])\n",
      "tensor([0.8075])\n",
      "tensor([0.8041])\n",
      "tensor([0.8041])\n",
      "tensor([0.7963])\n",
      "tensor([0.7899])\n",
      "tensor([0.7992])\n",
      "tensor([0.7990])\n",
      "tensor([0.7873])\n",
      "tensor([0.7801])\n",
      "tensor([0.7728])\n",
      "tensor([0.7848])\n",
      "tensor([0.7832])\n",
      "tensor([0.8253])\n",
      "tensor([0.8155])\n",
      "tensor([0.8154])\n",
      "tensor([0.8223])\n",
      "tensor([0.8207])\n",
      "tensor([0.7733])\n",
      "tensor([0.7625])\n",
      "tensor([0.7714])\n",
      "tensor([0.7688])\n",
      "tensor([0.7678])\n",
      "tensor([0.8274])\n",
      "tensor([0.8186])\n",
      "tensor([0.8148])\n",
      "tensor([0.8247])\n",
      "tensor([0.8228])\n",
      "tensor([0.8134])\n",
      "tensor([0.8049])\n",
      "tensor([0.7997])\n",
      "tensor([0.8095])\n",
      "tensor([0.8083])\n",
      "tensor([0.7833])\n",
      "tensor([0.7708])\n",
      "tensor([0.7766])\n",
      "tensor([0.7758])\n",
      "tensor([0.7770])\n",
      "tensor([0.7958])\n",
      "tensor([0.7836])\n",
      "tensor([0.7930])\n",
      "tensor([0.7887])\n",
      "tensor([0.7887])\n",
      "tensor([0.8016])\n",
      "tensor([0.7939])\n",
      "tensor([0.7898])\n",
      "tensor([0.7961])\n",
      "tensor([0.7969])\n",
      "tensor([0.7739])\n",
      "tensor([0.7658])\n",
      "tensor([0.7681])\n",
      "tensor([0.7688])\n",
      "tensor([0.7688])\n",
      "tensor([0.7792])\n",
      "tensor([0.7715])\n",
      "tensor([0.7646])\n",
      "tensor([0.7735])\n",
      "tensor([0.7738])\n",
      "tensor([0.7701])\n",
      "tensor([0.7604])\n",
      "tensor([0.7545])\n",
      "tensor([0.7644])\n",
      "tensor([0.7653])\n",
      "tensor([0.8021])\n",
      "tensor([0.7907])\n",
      "tensor([0.7898])\n",
      "tensor([0.7962])\n",
      "tensor([0.7962])\n",
      "tensor([0.7623])\n",
      "tensor([0.7507])\n",
      "tensor([0.7530])\n",
      "tensor([0.7556])\n",
      "tensor([0.7560])\n",
      "tensor([0.7520])\n",
      "tensor([0.7438])\n",
      "tensor([0.7362])\n",
      "tensor([0.7481])\n",
      "tensor([0.7479])\n",
      "tensor([0.7681])\n",
      "tensor([0.7578])\n",
      "tensor([0.7527])\n",
      "tensor([0.7644])\n",
      "tensor([0.7629])\n",
      "tensor([0.7706])\n",
      "tensor([0.7599])\n",
      "tensor([0.7570])\n",
      "tensor([0.7632])\n",
      "tensor([0.7637])\n",
      "tensor([0.7425])\n",
      "tensor([0.7324])\n",
      "tensor([0.7381])\n",
      "tensor([0.7387])\n",
      "tensor([0.7371])\n",
      "tensor([0.7234])\n",
      "tensor([0.7127])\n",
      "tensor([0.7150])\n",
      "tensor([0.7179])\n",
      "tensor([0.7178])\n",
      "tensor([0.7936])\n",
      "tensor([0.7840])\n",
      "tensor([0.7851])\n",
      "tensor([0.7886])\n",
      "tensor([0.7876])\n",
      "tensor([0.7790])\n",
      "tensor([0.7705])\n",
      "tensor([0.7726])\n",
      "tensor([0.7752])\n",
      "tensor([0.7732])\n",
      "tensor([0.7356])\n",
      "tensor([0.7252])\n",
      "tensor([0.7297])\n",
      "tensor([0.7301])\n",
      "tensor([0.7303])\n",
      "tensor([0.7959])\n",
      "tensor([0.7854])\n",
      "tensor([0.7827])\n",
      "tensor([0.7900])\n",
      "tensor([0.7873])\n",
      "tensor([0.7804])\n",
      "tensor([0.7704])\n",
      "tensor([0.7715])\n",
      "tensor([0.7760])\n",
      "tensor([0.7732])\n",
      "tensor([0.7649])\n",
      "tensor([0.7527])\n",
      "tensor([0.7537])\n",
      "tensor([0.7579])\n",
      "tensor([0.7562])\n",
      "tensor([0.7649])\n",
      "tensor([0.7517])\n",
      "tensor([0.7544])\n",
      "tensor([0.7572])\n",
      "tensor([0.7564])\n",
      "tensor([0.7683])\n",
      "tensor([0.7552])\n",
      "tensor([0.7578])\n",
      "tensor([0.7599])\n",
      "tensor([0.7591])\n",
      "tensor([0.7283])\n",
      "tensor([0.7134])\n",
      "tensor([0.7229])\n",
      "tensor([0.7197])\n",
      "tensor([0.7190])\n",
      "tensor([0.7602])\n",
      "tensor([0.7481])\n",
      "tensor([0.7536])\n",
      "tensor([0.7547])\n",
      "tensor([0.7516])\n",
      "tensor([0.7770])\n",
      "tensor([0.7644])\n",
      "tensor([0.7660])\n",
      "tensor([0.7715])\n",
      "tensor([0.7679])\n",
      "tensor([0.7417])\n",
      "tensor([0.7276])\n",
      "tensor([0.7412])\n",
      "tensor([0.7361])\n",
      "tensor([0.7340])\n",
      "tensor([0.7422])\n",
      "tensor([0.7284])\n",
      "tensor([0.7349])\n",
      "tensor([0.7358])\n",
      "tensor([0.7326])\n",
      "tensor([0.7681])\n",
      "tensor([0.7530])\n",
      "tensor([0.7569])\n",
      "tensor([0.7622])\n",
      "tensor([0.7600])\n",
      "tensor([0.7402])\n",
      "tensor([0.7294])\n",
      "tensor([0.7290])\n",
      "tensor([0.7329])\n",
      "tensor([0.7335])\n",
      "tensor([0.7643])\n",
      "tensor([0.7528])\n",
      "tensor([0.7539])\n",
      "tensor([0.7570])\n",
      "tensor([0.7579])\n",
      "tensor([0.7023])\n",
      "tensor([0.6936])\n",
      "tensor([0.7005])\n",
      "tensor([0.6996])\n",
      "tensor([0.6985])\n",
      "tensor([0.7648])\n",
      "tensor([0.7541])\n",
      "tensor([0.7546])\n",
      "tensor([0.7571])\n",
      "tensor([0.7574])\n",
      "tensor([0.7378])\n",
      "tensor([0.7281])\n",
      "tensor([0.7205])\n",
      "tensor([0.7331])\n",
      "tensor([0.7322])\n",
      "tensor([0.7636])\n",
      "tensor([0.7531])\n",
      "tensor([0.7551])\n",
      "tensor([0.7596])\n",
      "tensor([0.7578])\n",
      "tensor([0.7031])\n",
      "tensor([0.6946])\n",
      "tensor([0.6937])\n",
      "tensor([0.6995])\n",
      "tensor([0.6987])\n",
      "tensor([0.7431])\n",
      "tensor([0.7351])\n",
      "tensor([0.7320])\n",
      "tensor([0.7390])\n",
      "tensor([0.7378])\n",
      "tensor([0.7230])\n",
      "tensor([0.7118])\n",
      "tensor([0.7189])\n",
      "tensor([0.7177])\n",
      "tensor([0.7163])\n",
      "tensor([0.7377])\n",
      "tensor([0.7279])\n",
      "tensor([0.7243])\n",
      "tensor([0.7333])\n",
      "tensor([0.7323])\n",
      "tensor([0.7595])\n",
      "tensor([0.7523])\n",
      "tensor([0.7496])\n",
      "tensor([0.7555])\n",
      "tensor([0.7546])\n",
      "tensor([0.7389])\n",
      "tensor([0.7296])\n",
      "tensor([0.7251])\n",
      "tensor([0.7340])\n",
      "tensor([0.7331])\n",
      "tensor([0.7256])\n",
      "tensor([0.7159])\n",
      "tensor([0.7136])\n",
      "tensor([0.7218])\n",
      "tensor([0.7201])\n",
      "tensor([0.7235])\n",
      "tensor([0.7146])\n",
      "tensor([0.7122])\n",
      "tensor([0.7184])\n",
      "tensor([0.7189])\n",
      "tensor([0.7158])\n",
      "tensor([0.7065])\n",
      "tensor([0.7072])\n",
      "tensor([0.7103])\n",
      "tensor([0.7094])\n",
      "tensor([0.7388])\n",
      "tensor([0.7296])\n",
      "tensor([0.7274])\n",
      "tensor([0.7342])\n",
      "tensor([0.7315])\n",
      "tensor([0.7038])\n",
      "tensor([0.6925])\n",
      "tensor([0.6947])\n",
      "tensor([0.6983])\n",
      "tensor([0.6965])\n",
      "tensor([0.7422])\n",
      "tensor([0.7308])\n",
      "tensor([0.7328])\n",
      "tensor([0.7369])\n",
      "tensor([0.7356])\n",
      "tensor([0.7614])\n",
      "tensor([0.7509])\n",
      "tensor([0.7505])\n",
      "tensor([0.7563])\n",
      "tensor([0.7555])\n",
      "tensor([0.6917])\n",
      "tensor([0.6817])\n",
      "tensor([0.6888])\n",
      "tensor([0.6868])\n",
      "tensor([0.6878])\n",
      "tensor([0.6974])\n",
      "tensor([0.6873])\n",
      "tensor([0.6883])\n",
      "tensor([0.6918])\n",
      "tensor([0.6901])\n",
      "tensor([0.6890])\n",
      "tensor([0.6787])\n",
      "tensor([0.6820])\n",
      "tensor([0.6829])\n",
      "tensor([0.6825])\n",
      "tensor([0.7318])\n",
      "tensor([0.7221])\n",
      "tensor([0.7217])\n",
      "tensor([0.7268])\n",
      "tensor([0.7246])\n",
      "tensor([0.7152])\n",
      "tensor([0.7043])\n",
      "tensor([0.7110])\n",
      "tensor([0.7108])\n",
      "tensor([0.7093])\n",
      "tensor([0.7080])\n",
      "tensor([0.6960])\n",
      "tensor([0.6997])\n",
      "tensor([0.7010])\n",
      "tensor([0.6997])\n",
      "tensor([0.7228])\n",
      "tensor([0.7135])\n",
      "tensor([0.7051])\n",
      "tensor([0.7190])\n",
      "tensor([0.7168])\n",
      "tensor([0.7036])\n",
      "tensor([0.6970])\n",
      "tensor([0.6908])\n",
      "tensor([0.7001])\n",
      "tensor([0.6977])\n",
      "tensor([0.6629])\n",
      "tensor([0.6557])\n",
      "tensor([0.6608])\n",
      "tensor([0.6603])\n",
      "tensor([0.6592])\n",
      "tensor([0.6996])\n",
      "tensor([0.6914])\n",
      "tensor([0.6905])\n",
      "tensor([0.6957])\n",
      "tensor([0.6939])\n",
      "tensor([0.7144])\n",
      "tensor([0.7081])\n",
      "tensor([0.7019])\n",
      "tensor([0.7093])\n",
      "tensor([0.7085])\n",
      "tensor([0.6995])\n",
      "tensor([0.6880])\n",
      "tensor([0.6897])\n",
      "tensor([0.6910])\n",
      "tensor([0.6903])\n",
      "tensor([0.6871])\n",
      "tensor([0.6804])\n",
      "tensor([0.6778])\n",
      "tensor([0.6819])\n",
      "tensor([0.6810])\n",
      "tensor([0.6816])\n",
      "tensor([0.6757])\n",
      "tensor([0.6719])\n",
      "tensor([0.6790])\n",
      "tensor([0.6767])\n",
      "tensor([0.7128])\n",
      "tensor([0.7071])\n",
      "tensor([0.7023])\n",
      "tensor([0.7112])\n",
      "tensor([0.7077])\n",
      "tensor([0.7040])\n",
      "tensor([0.6988])\n",
      "tensor([0.6931])\n",
      "tensor([0.7023])\n",
      "tensor([0.6992])\n",
      "tensor([0.6675])\n",
      "tensor([0.6578])\n",
      "tensor([0.6581])\n",
      "tensor([0.6630])\n",
      "tensor([0.6612])\n",
      "tensor([0.6925])\n",
      "tensor([0.6836])\n",
      "tensor([0.6791])\n",
      "tensor([0.6885])\n",
      "tensor([0.6869])\n",
      "tensor([0.7026])\n",
      "tensor([0.6948])\n",
      "tensor([0.6881])\n",
      "tensor([0.7002])\n",
      "tensor([0.6973])\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for token, token_activation in zip(tokenized[\"input_ids\"][0],extracted[0]):\n",
    "    token_as_word = tokenizer.decode(token).strip()\n",
    "    #print(token_activation)\n",
    "    current_max_similarity = 0\n",
    "    most_similar_language = None\n",
    "    for language, average_activation in average_vectors.items():\n",
    "        similarity = F.cosine_similarity(average_activation.cpu().unsqueeze(0), token_activation.cpu().unsqueeze(0))\n",
    "        print(similarity)\n",
    "        if current_max_similarity < similarity:\n",
    "            current_max_similarity = similarity\n",
    "            most_similar_language = language\n",
    "    li.append((current_max_similarity,most_similar_language, token_as_word))\n",
    "        \n",
    "input_text = li       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, None, 'The'),\n",
       " (tensor([0.7734]), 'en', 'cat'),\n",
       " (tensor([0.8046]), 'en', '('),\n",
       " (tensor([0.8039]), 'en', 'F'),\n",
       " (tensor([0.7660]), 'sv', 'elis'),\n",
       " (tensor([0.7944]), 'sv', 'c'),\n",
       " (tensor([0.7773]), 'en', 'atus'),\n",
       " (tensor([0.8168]), 'en', '),'),\n",
       " (tensor([0.8057]), 'en', 'also'),\n",
       " (tensor([0.7497]), 'en', 'referred'),\n",
       " (tensor([0.7985]), 'en', 'to'),\n",
       " (tensor([0.8312]), 'en', 'as'),\n",
       " (tensor([0.8415]), 'en', 'the'),\n",
       " (tensor([0.8158]), 'en', 'domestic'),\n",
       " (tensor([0.7725]), 'en', 'cat'),\n",
       " (tensor([0.8278]), 'en', 'or'),\n",
       " (tensor([0.8008]), 'en', 'house'),\n",
       " (tensor([0.7866]), 'en', 'cat'),\n",
       " (tensor([0.8270]), 'en', ','),\n",
       " (tensor([0.7950]), 'en', 'is'),\n",
       " (tensor([0.8061]), 'en', 'a'),\n",
       " (tensor([0.7911]), 'en', 'small'),\n",
       " (tensor([0.7693]), 'en', 'dom'),\n",
       " (tensor([0.7658]), 'en', 'est'),\n",
       " (tensor([0.8134]), 'en', 'icated'),\n",
       " (tensor([0.7659]), 'en', 'carn'),\n",
       " (tensor([0.7630]), 'en', 'ivor'),\n",
       " (tensor([0.8112]), 'en', 'ous'),\n",
       " (tensor([0.7761]), 'en', 'mamm'),\n",
       " (tensor([0.7716]), 'en', 'al'),\n",
       " (tensor([0.7451]), 'en', '.'),\n",
       " (tensor([0.7681]), 'en', 'It'),\n",
       " (tensor([0.7829]), 'en', 'is'),\n",
       " (tensor([0.7857]), 'en', 'the'),\n",
       " (tensor([0.7770]), 'en', 'only'),\n",
       " (tensor([0.7689]), 'en', 'dom'),\n",
       " (tensor([0.7741]), 'en', 'est'),\n",
       " (tensor([0.8104]), 'en', 'icated'),\n",
       " (tensor([0.7624]), 'en', 'species'),\n",
       " (tensor([0.7844]), 'en', 'of'),\n",
       " (tensor([0.7814]), 'en', 'the'),\n",
       " (tensor([0.7456]), 'en', 'family'),\n",
       " (tensor([0.7153]), 'is', 'Fel'),\n",
       " (tensor([0.7380]), 'en', 'idae'),\n",
       " (tensor([0.7256]), 'en', '.'),\n",
       " (tensor([0.7213]), 'en', 'Ad'),\n",
       " (tensor([0.7001]), 'en', 'van'),\n",
       " (tensor([0.7274]), 'en', 'ces'),\n",
       " (tensor([0.7527]), 'en', 'in'),\n",
       " (tensor([0.7135]), 'en', 'archae'),\n",
       " (tensor([0.7588]), 'en', 'ology'),\n",
       " (tensor([0.7828]), 'en', 'and'),\n",
       " (tensor([0.7141]), 'en', 'genet'),\n",
       " (tensor([0.7567]), 'en', 'ics'),\n",
       " (tensor([0.7508]), 'en', 'have'),\n",
       " (tensor([0.7340]), 'en', 'shown'),\n",
       " (tensor([0.7650]), 'en', 'that'),\n",
       " (tensor([0.7564]), 'en', 'the'),\n",
       " (tensor([0.7077]), 'en', 'dom'),\n",
       " (tensor([0.7082]), 'en', 'est'),\n",
       " (tensor([0.7216]), 'en', 'ication'),\n",
       " (tensor([0.7612]), 'en', 'of'),\n",
       " (tensor([0.7703]), 'sv', 'the'),\n",
       " (tensor([0.6999]), 'en', 'cat'),\n",
       " (tensor([0.7136]), 'en', 'occurred'),\n",
       " (tensor([0.7517]), 'en', 'in'),\n",
       " (tensor([0.7484]), 'en', 'the'),\n",
       " (tensor([0.6843]), 'is', 'Near'),\n",
       " (tensor([0.7055]), 'en', 'East'),\n",
       " (tensor([0.7091]), 'en', 'around'),\n",
       " (tensor([0.7236]), 'en', ''),\n",
       " (tensor([0.7329]), 'en', '7'),\n",
       " (tensor([0.7357]), 'en', '5'),\n",
       " (tensor([0.7103]), 'en', '0'),\n",
       " (tensor([0.6908]), 'en', '0'),\n",
       " (tensor([0.6750]), 'en', 'BC'),\n",
       " (tensor([0.6894]), 'en', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [float(str(t[0]).strip('tensor([])')) for t in input_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
