{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from refactor.probes import model_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/267bnxr16cq2xpr1crtpxbgw0000gn/T/ipykernel_4552/1524319005.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/267bnxr16cq2xpr1crtpxbgw0000gn/T/ipykernel_4552/1524319005.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/267bnxr16cq2xpr1crtpxbgw0000gn/T/ipykernel_4552/1524319005.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/267bnxr16cq2xpr1crtpxbgw0000gn/T/ipykernel_4552/1524319005.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"gpt_gptsw3_en_da_356m_gbs1024\",\"gpt_gptsw3_en_da_is_356m_gbs1024\",\"gpt_gptsw3_en_is_da_356m_gbs1024\",\"gpt_sw3_356m\"]\n",
    "lambda_val = 5\n",
    "layer = \"transformer.h.15.ln_1.bias\"\n",
    "for model_name in model_names:\n",
    "    \n",
    "    model_path = \"downloaded_models/\"\n",
    "\n",
    "    model, tokenizer, device = model_setup(f\"{model_path}{model_name}\")\n",
    "    \n",
    "    steering = torch.load(f\"steering_vectors/{model_name}/combined_steering_vector_layer_15_tensor.pt\",map_location = device)\n",
    "    \n",
    "    model.state_dict()[layer] += steering*lambda_val\n",
    "    \n",
    "    model.save_pretrained(f'{model_path}/{model_name}_with_steering_lambda_{lambda_val}')\n",
    "    tokenizer.save_pretrained(f'{model_path}/{model_name}_with_steering_lambda_{lambda_val}')  # Optional but recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/data/steering_data_bible/bible_data_combined.csv\")\n",
    "df = df[(df.layer == 15) & (df.lambda_amount == 5)]\n",
    "temp =pd.read_csv(\"results\\data\\steering_data_bible\\combined_english_without_steering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31215                                       .<|endoftext|>\n",
       "14655     muref, andr, shamam, kutah, pabu, mureh, andr...\n",
       "25527                     +) 13158: 319. +) 13217: 320. +)\n",
       "26679     sjelen avlede sjele, a, s, m, 1939\\n-avlede s...\n",
       "36039     de barabahaen, den haferuahen, shemna, shofar...\n",
       "3447                                        .<|endoftext|>\n",
       "48543     -> 31But the third, fourth and fifth days, as...\n",
       "495                                         .<|endoftext|>\n",
       "43863     ->\\nIn the end all creatures on the earth wer...\n",
       "25575     Denne sønn ble gift en gang, og med ham blev ...\n",
       "Name: danish_predicted_output, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.danish_prompt_score < 0.6].sample(10)[\"danish_predicted_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.danish_prompt_score < 0.6].sample(10)[\"danish_predicted_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18567      13. dansk: Dette gælder også for produkter, ...\n",
       "34119    \" på Dansk.  Den tredje gang sagde Gud til Ada...\n",
       "14031                                                  ...\n",
       "39159        For en kort tid, er det kun de to børn, so...\n",
       "41799        Engelsk: \"November 1984\" er en serie af 12...\n",
       "36999     og hver fugl på himlen, og bragt dem til mand...\n",
       "11703        20. 30% af de danske børn får nemlig deres...\n",
       "42687        TIL    1. Den Hellige Ånd er den eneste sa...\n",
       "40479     de havde to små børn. de havde ingen penge. d...\n",
       "47247    . ->  engelsk  Og da sagde Herren til Moses: S...\n",
       "Name: english_predicted_output, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.english_prompt_score < 0.6].sample(10)[\"english_predicted_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    18. På den anden side er den ikke lige så god som sin forgænger. ->  On den anden side er den ikke lige så god som forgængeren.    19. Du kan ikke bruge din egen hånd til at gøre det, men med en hånd, kan du være i stand til at gøre det, som du ønsker. ->  Du kan ikke bruge din egen'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.danish_language_prediction_on_english_steered > 0.7].sample(10).english_predicted_output.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
