{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.probe_confidence_intervals import model_setup, get_activations\n",
    "from utils.preprocessing import load_txt_data\n",
    "from pathlib import Path\n",
    "from classes.datahandling import TextClassificationDataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from classes.hook_manager import HookManager\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "Load data\n"
     ]
    }
   ],
   "source": [
    "print(\"Load model\")\n",
    "model_name  = \"AI-Sweden-Models/gpt-sw3-356m\"\n",
    "\n",
    "model, tokenizer, device = model_setup(model_name)\n",
    "\n",
    "raw_data_folder = Path('data/antibiotic/')\n",
    "print(\"Load data\")\n",
    "ds = load_txt_data(\n",
    "    file_paths={\n",
    "        'da': raw_data_folder / 'da.txt',\n",
    "        'en': raw_data_folder / 'en.txt',\n",
    "        'sv': raw_data_folder / 'sv.txt',\n",
    "        'nb': raw_data_folder / 'nb.txt',\n",
    "        'is': raw_data_folder / 'is.txt'\n",
    "    },\n",
    "    file_extension='txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = {}\n",
    "meta_data[\"hidden_layers\"] = model.config.num_hidden_layers\n",
    "\n",
    "try:\n",
    "    meta_data[\"hidden_size\"] = model.config.n_embd\n",
    "except AttributeError:\n",
    "    meta_data[\"hidden_size\"] = model.config.hidden_size\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      " 23%|██▎       | 6/26 [00:35<01:57,  5.86s/it]\n",
      " 20%|██        | 6/30 [00:26<01:46,  4.42s/it]\n",
      " 20%|██        | 6/30 [00:36<02:27,  6.16s/it]\n",
      " 32%|███▏      | 6/19 [00:33<01:12,  5.59s/it]\n",
      " 23%|██▎       | 6/26 [00:54<03:02,  9.14s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_all_steering_vectors(ds: TextClassificationDataset, \n",
    "                         languages:list,\n",
    "                         meta_data: dict,\n",
    "                         tokenizer: AutoTokenizer,\n",
    "                         device: str,\n",
    "                         model: AutoModelForCausalLM) -> dict:\n",
    "    d = dict()\n",
    "    for lang in languages:\n",
    "        \n",
    "        filtered_ds = ds.filter_by_language(lang)\n",
    "        loader = DataLoader(filtered_ds, batch_size=32, shuffle=True)\n",
    "        activation_ds_by_layer = get_activations(meta_data,loader, tokenizer, device, model)\n",
    "        #Each key has a list of averaged activations meaning that d['en'][2] is the english steering vector\n",
    "        #for the 2nd layer\n",
    "        d[lang] = [torch.stack(layer.predictors).mean(dim=0) for layer in activation_ds_by_layer.values()]\n",
    "    return d\n",
    "\n",
    "languages = [\"da\",\"en\",\"sv\",\"nb\",\"is\"]\n",
    "all_steering_vectos = compute_all_steering_vectors(ds,languages,meta_data, tokenizer, device, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_vectors(all_steering_vectos:dict,target_language: str, complement_languages:list) -> []:\n",
    "    temp_d = defaultdict(list)\n",
    "\n",
    "    for lang in complement_languages:\n",
    "        for layer, vector in enumerate(all_steering_vectos[lang]):\n",
    "            temp_d[layer].append(vector)\n",
    "    #We represent it as dicts so that it is clear that each key is a layer\n",
    "    complement_steering_vectors = {layer: torch.stack(value).mean(dim=0) for layer, value in temp_d.items()}\n",
    "    target_steering_vectors = {i: all_steering_vectos[\"da\"][i] for i in range(len(all_steering_vectos[\"da\"]))}\n",
    "    return target_steering_vectors, complement_steering_vectors\n",
    "    \n",
    "target_steering_vectors, complement_steering_vectors = get_steering_vectors(all_steering_vectos, \"da\", [\"en\",\"sv\",\"nb\",\"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vector_dict = dict()\n",
    "for layer, vectors in enumerate(zip(target_steering_vectors.values(),complement_steering_vectors.values() )):\n",
    "    target_vector = vectors[0]\n",
    "    complement_vector = vectors[1]\n",
    "    combined = target_vector - complement_vector\n",
    "    combined_vector_dict[layer] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why can we subtract a feature but not aplify a feature\n",
    "#talk about other steering method https://arxiv.org/html/2402.01618v1#S3.SS1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a short story about 2 teenage piger. Denise: Denise:<|endoftext|>\n",
      "\n",
      " This is a short story about 2 friends, 2 dage efter en skudepisode, hvor en af dem blev skudt i hovedet, og det er også en kort historie om en mand, som har slået en anden mand ihjel.  Jeg håber, I kan lide den!  Mvh.  Thea<|endoftext|>\n",
      "\n",
      "This is a short story about 25 år, der bor i et stort hus sammen med deres mor, far og tre søskende. Det er en hverdag, hvor man skal være sammen med sine forældre, og det er svært. Det er en hverdag, hvor man skal passe på, hvad man siger og gør. Det er en hverdag, hvor\n",
      "\n",
      "This is a short story about 20-årige Frederik, der har en særlig plads i hjertet hos sine forældre. En dag bliver Frederik kidnappet af en flok teenagere, der er ude på at kidnappe ham. Frederik vil ikke være alene, og han vil helst være sammen med sin bedste ven, Sebastian. Sebastian er nemlig forelsket i en\n",
      "\n",
      "This is a short story about 12-year-old Dalton, who has to live in a house with his mother.  The story handler fortæller om, hvordan det er at vokse op som barn i et hjem, hvor far og mor er alkoholikere. -> The story tells about how it is to grow up as a child in\n",
      "\n",
      "This is a short story about 23-year-old Jacob, who is a struggling student.    \"I'm in high school, and I'm a good student. Jeg er i gang med at læse en bog, og jeg er nødt til at læse den færdig. -> \"I'm in high school and\n",
      "\n",
      "This is a short story about 2 drenge der er i skole. En pige og en dreng. De er begge meget dygtige til matematik. Den ene er dygtig til matematik og den anden er ikke så dygtig. Det er en pige der er dygtig til matematik. Den anden er ikke så dygtig. Den ene dreng bliver mobbet af den anden.\n",
      "\n",
      "This is a short story about 2 teenage piger, som prøver at finde sig selv. I deres tanker er det svært at finde sig selv. De er usikre og vil helst være alene, men de ved ikke, hvordan de skal komme af med det. De prøver at finde sig selv, men det er svært. Jeg hedder Julie, jeg er\n",
      "\n",
      "This is a short story about 13-year-old Lila.  Lila er en lille, men meget sød pige. -> Lila is a small, but very cute girl.  Han har en søn på 2 år. -> He has a son of 2 years.  Så hvis du har\n",
      "\n",
      "This is a short story about 2 teenagers, who harbour their undying love for hinanden. Dansk: Jeg er selv forelsket i en pige. Dansk: Jeg er forelsket i en pige. Dansk: Jeg ved ikke, hvad der er sket med mit hjerte. Dansk: Jeg ved ikke, hvad der er sket med mit hjerte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = 'This is a short story about '\n",
    "tokenized = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "with HookManager(model) as hook_manager:\n",
    "    layer = 14\n",
    "    \n",
    "    hook_manager.attach_residual_stream_activation_based_steering_vector(\n",
    "        layer,\n",
    "        combined_vector_dict[layer],\n",
    "        plus = True,\n",
    "        scalar = 5,\n",
    "        pre_mlp=False,\n",
    "        pythia=False  \n",
    "    )\n",
    "\n",
    "\n",
    "    output_nb_steering = [\n",
    "        model.generate(tokenized.input_ids, max_length=70, temperature=0.7, top_p=0.9, do_sample=True)\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "for output in output_nb_steering:\n",
    "    print(tokenizer.decode(output[0]).replace('\\n', ' '))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
