{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    has_changed_dir\n",
    "except:\n",
    "    has_changed_dir = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install datasets\n",
    "    %pip install translate-toolkit\n",
    "    %pip install bitsandbytes\n",
    "\n",
    "    !git clone https://github.com/MartinKirkegaard/KDS_MI.git\n",
    "\n",
    "    if not has_changed_dir:\n",
    "        os.chdir('KDS_MI')\n",
    "        has_changed_dir = True\n",
    "else:\n",
    "    if not has_changed_dir:\n",
    "        os.chdir('.')\n",
    "        has_changed_dir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from classification_probes import TextClassificationDataset, ProbeTrainer, HookManager, ClassificationProbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roneneldan/TinyStories-1M\"\n",
    "model_name = \"EleutherAI/pythia-14m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "try:\n",
    "    hidden_size = model.config.n_embd\n",
    "except AttributeError:\n",
    "    hidden_size = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 128)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXSdpaAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "  )\n",
       "  (embed_out): Linear(in_features=128, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_map = {\n",
    "    'da': 0,\n",
    "    'en': 1,\n",
    "    'is': 2,\n",
    "    'nb': 3,\n",
    "    'sv': 4\n",
    "}\n",
    "\n",
    "data_loc = 'data/antibiotic/'\n",
    "ds = TextClassificationDataset.from_txt(data_loc + 'da.txt', lab_map['da'])\n",
    "ds.add_from_txt(data_loc + 'en.txt', lab_map['en'])\n",
    "ds.add_from_txt(data_loc + 'is.txt', lab_map['is'])\n",
    "ds.add_from_txt(data_loc + 'nb.txt', lab_map['nb'])\n",
    "ds.add_from_txt(data_loc + 'sv.txt', lab_map['sv'])\n",
    "\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dataset that can hold the activations and labels.\n",
    "\n",
    "class ActivationDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.acts = []\n",
    "        self.labels = []\n",
    "\n",
    "    def add_with_mask(self, acts, labels, masks):\n",
    "        for act, label, mask in zip(acts, labels, masks):\n",
    "            if mask:\n",
    "                self.acts.append(act)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        return (self.acts[index], self.labels[index]) \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.acts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m HookManager(model) \u001b[38;5;28;01mas\u001b[39;00m hook_manager:\n\u001b[0;32m     13\u001b[0m     res_stream_act \u001b[38;5;241m=\u001b[39m hook_manager\u001b[38;5;241m.\u001b[39mattach_residstream_hook(\n\u001b[0;32m     14\u001b[0m         layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     15\u001b[0m         pre_mlp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m         pythia\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# flattening [batch, pad_size, ...] to [tokens, ...]\u001b[39;00m\n\u001b[0;32m     22\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m tokenized\u001b[38;5;241m.\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;66;03m# [tokens]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:1173\u001b[0m, in \u001b[0;36mGPTNeoXForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;124;03m    Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;124;03m>>> prediction_logits = outputs.logits\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_neox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1188\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_out(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:946\u001b[0m, in \u001b[0;36mGPTNeoXModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    933\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    934\u001b[0m         layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    935\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m         position_embeddings,\n\u001b[0;32m    944\u001b[0m     )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 946\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:693\u001b[0m, in \u001b[0;36mGPTNeoXLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions, cache_position, position_embeddings)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    683\u001b[0m     hidden_states: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m     position_embeddings: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# will become mandatory in v4.46\u001b[39;00m\n\u001b[0;32m    692\u001b[0m ):\n\u001b[1;32m--> 693\u001b[0m     attention_layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attention_layer_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: attn_output, present, (attn_weights)\u001b[39;00m\n\u001b[0;32m    705\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_dropout(attn_output)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:319\u001b[0m, in \u001b[0;36mGPTNeoXAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, head_mask, layer_past, use_cache, output_attentions, padding_mask, cache_position, position_embeddings)\u001b[0m\n\u001b[0;32m    316\u001b[0m bsz, seq_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Apply attention-specific projections and rope\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m query, key, value, present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn_projections_and_rope\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Checking for fallbacks in case an unsupported feature is requested\u001b[39;00m\n\u001b[0;32m    329\u001b[0m attention_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\models\\gpt_neox\\modeling_gpt_neox.py:441\u001b[0m, in \u001b[0;36mGPTNeoXAttention._attn_projections_and_rope\u001b[1;34m(self, hidden_states, position_ids, layer_past, use_cache, cache_position, position_embeddings)\u001b[0m\n\u001b[0;32m    439\u001b[0m     cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m    440\u001b[0m query, key \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_rot, key_rot, cos, sin)\n\u001b[1;32m--> 441\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_pass\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((key, key_pass), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Cache QKV values\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation_ds = ActivationDataset()\n",
    "\n",
    "for text, label in loader:\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    with HookManager(model) as hook_manager:\n",
    "        res_stream_act = hook_manager.attach_residstream_hook(\n",
    "            layer=4,\n",
    "            pre_mlp=False,\n",
    "            pythia=True\n",
    "        )\n",
    "\n",
    "        model(**tokenized)\n",
    "    \n",
    "    # flattening [batch, pad_size, ...] to [tokens, ...]\n",
    "    attn_mask = tokenized.attention_mask.flatten() # [tokens]\n",
    "    label = label.unsqueeze(-1).expand(-1, tokenized.attention_mask.shape[1]).flatten() # [tokens]\n",
    "    res_stream_act = res_stream_act[0].view(-1, hidden_size) # [tokens, hidden_size]\n",
    "\n",
    "    activation_ds.add_with_mask(res_stream_act, label, attn_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = [int(act) for act in activation_ds.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_loader = DataLoader(activation_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6708, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6358, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5314, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5318, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5155, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5811, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4742, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5644, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5788, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4340, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4144, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3550, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4459, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3304, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3752, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5393, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2519, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4698, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5396, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2810, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3564, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2757, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4333, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4109, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3666, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3635, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3525, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1790, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4790, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2293, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3828, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2818, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3367, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3785, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1716, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3757, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2366, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2752, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3324, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1517, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3905, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3355, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2313, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2799, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2764, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3970, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2957, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2682, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2819, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1819, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2654, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2774, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1776, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1766, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2681, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1790, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1635, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3364, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1539, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3661, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1781, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3345, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1483, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1827, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1519, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2316, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2629, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1196, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1757, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2175, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2355, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2552, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1167, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1815, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3485, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1788, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2568, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2681, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1342, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1809, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2537, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2788, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2324, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1811, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1593, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1358, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2692, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2698, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2801, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2601, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1724, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2665, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1692, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2107, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0844, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1519, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2410, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2724, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1905, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2347, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2766, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2672, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0548, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0635, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1573, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1719, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1622, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2504, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1907, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2358, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1724, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1395, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1364, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1175, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1957, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1128, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1719, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1785, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1811, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1537, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1779, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1608, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2708, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1485, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0828, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2556, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1293, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1781, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2705, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2915, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1668, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2750, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0678, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1640, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3353, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_size = hidden_size\n",
    "learning_rate = 0.001\n",
    "reg_lambda = 0.1\n",
    "num_labs = len(lab_map)\n",
    "\n",
    "probe = ClassificationProbe(in_dim=input_size, num_labs=num_labs, device='cpu')\n",
    "optimizer = torch.optim.Adam(probe.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for act, label in act_loader:\n",
    "\n",
    "        outputs = probe(act)\n",
    "        loss = loss_fn(outputs, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arranged in six parts, the film depicts a strike in 1903 by the workers of a factory in pre-revolutionary Russia, and their subsequent suppression. It is best known for a sequence towards the climax, in which the violent and violent events are made.\\n\\nThe film is a film, a film, a film, a film, a film, a film, a film, a film, a film, a film, a film, a film, a film, a film,'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector = probe.linear._parameters['weight'][3]\n",
    "\n",
    "text = 'Arranged in six parts, the film depicts a strike in 1903 by the workers of a factory in pre-revolutionary Russia, and their subsequent suppression. It is best known for a sequence towards the climax, in which the violent'\n",
    "tokenized = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "with HookManager(model) as hook_manager:\n",
    "    hook_manager.attach_resid_stream_steer_hook(\n",
    "        4,\n",
    "        steering_vector,\n",
    "        3,\n",
    "        pre_mlp=False,\n",
    "        pythia=True\n",
    "    )\n",
    "\n",
    "    output = model.generate(tokenized.input_ids, max_length=100, temperature=0.7, top_p=0.9, do_sample=False)\n",
    "\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arranged in six parts, the film depicts a strike in 1903 by the workers of a factory in pre-revolutionary Russia, and their subsequent suppression. It is best known for a sequence towards the climax, in which the violent and violent of the Soviet Union was the first to be seen.\\n\\nThe film is a film that is a film that is a film that is a film that is a film that is a film that is a film that is a film that is a film that'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(tokenized.input_ids, max_length=100, temperature=0.7, top_p=0.9, do_sample=False)\n",
    "\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7047,  3767, 30912,    75,   413,  2827,   546,  1448,  6706,   546,\n",
       "          2098, 14293,    85,  1151,   466,   891,   726,    87, 33578,  1129,\n",
       "          8225,  5025,   346,    49,  2768,  1670,    75,   771,   354,  1059,\n",
       "         33325,  1507,  1073,  5751,  4953,     3,  9040,   945,  1162,   269,\n",
       "          5507,   620,   265,  1775,   274,  1257,    75,   615,   278,  4415,\n",
       "            78,    15,   187,   187,    34,    27,   187,   187,   510,   806,\n",
       "          3213,   310,   281,  1918,   368,   247,  2372,   273,   247, 12662,\n",
       "           285,   923,   752,   253,  3662,    27,   187,   187,    14, 50275,\n",
       "           187,   187,    14, 50275,   187,   187,    14, 50275,   187,   187,\n",
       "            14, 50275,   187,   187,    14, 50275,   187,   187,    14, 50275]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filmen Strejke er en del af en planlagt serie i syv dele med titlen \"På vej mod proletariatets diktatur\" og var et fælles samarbejde mellem.\\n\\nA:\\n\\nThe first step is to give you a bit of a hint and see what the answer:\\n\\n-   \\n\\n-   \\n\\n-   \\n\\n-   \\n\\n-   \\n\\n-   '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_magnitudes = (act.unsqueeze(0) @ steering_vector).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector_ = steering_vector.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0383],\n",
       "         [ 3.2407],\n",
       "         [ 4.7199],\n",
       "         [-0.4780],\n",
       "         [ 4.3807],\n",
       "         [-3.7402],\n",
       "         [ 1.0187],\n",
       "         [ 8.1848],\n",
       "         [-1.3870],\n",
       "         [ 1.7934],\n",
       "         [ 0.7859],\n",
       "         [-3.5573],\n",
       "         [-0.1791],\n",
       "         [ 2.3834]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = (projection_magnitudes * steering_vector_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 3, 1, 4, 1, 2, 2, 4, 0, 2, 2, 1, 4, 4, 1, 4, 0, 4, 4, 1, 4, 0, 1,\n",
       "        1, 4, 2, 2, 0, 3, 2, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2,  ..., 4, 4, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.unsqueeze(-1).expand(-1, tokenized.attention_mask.shape[1]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4928])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.attention_mask.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5304,  0.9247, -0.0046, -2.0886,  0.9416, -0.6766,  1.6014,  0.4292,\n",
       "        -0.3467,  0.6638, -0.3799, -3.7725,  0.0168, -0.6235,  1.7516,  1.1082,\n",
       "         0.2715,  0.7788,  0.1381,  0.3071,  1.7841,  0.8833, -0.9052,  0.7601,\n",
       "        -1.4813,  0.8397, -2.0588, -0.9006, -0.7124,  0.6576, -1.1364,  1.0030,\n",
       "         0.6364,  1.6032,  0.4388, -1.4383,  0.8074,  3.0726,  0.0916, -0.9084,\n",
       "         0.0775,  1.0104, -0.6060, -0.0836, -2.3467, -4.3569,  2.1628,  1.2648,\n",
       "        -0.7746, -0.0214,  1.1413, -0.5092, -2.0130,  0.4083, -2.4431, -1.1179,\n",
       "         0.5212,  0.7194, -0.6159, -0.8679,  0.7901,  1.3831,  0.0591,  0.8055])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_stream_act[0].view(-1, hidden_size)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 154, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_stream_act[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = ProbeTrainer(hidden_size, 5, 0.001, 0.1, 'cpu')\n",
    "\n",
    "for text_batch, labels in loader:\n",
    "    print(text)\n",
    "    with HookManager(model) as hook_manager:\n",
    "        res_stream_act = hook_manager.attach_residstream_hook(\n",
    "            layer=4,\n",
    "            pre_mlp=False\n",
    "        )\n",
    "\n",
    "        tokenized = [\n",
    "            tokenizer(text, return_tensors='pt')\n",
    "            for text in text_batch\n",
    "        ]\n",
    "        for text in tokenized:\n",
    "            model.forward(**text)\n",
    "\n",
    "    loss = trainer.train_step(torch.Tensor(res_stream_act), torch.Tensor(labels))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPTNeoConfig' object has no attribute 'n_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_embed\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\Code\\mechinterp\\mechinterp\\Lib\\site-packages\\transformers\\configuration_utils.py:210\u001b[0m, in \u001b[0;36mPretrainedConfig.__getattribute__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)[key]\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GPTNeoConfig' object has no attribute 'n_embed'"
     ]
    }
   ],
   "source": [
    "model.config.n_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(64000, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=64000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule('transformer.h.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = \"dette er en\"\n",
    "\n",
    "tokenized = tokenizer(input_, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1122,  358,  315]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = model.generate(tokenized.input_ids, max_length=100, temperature=0.7, top_p=0.9, do_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
